Jurka_02_cancer_RTextTools
==================================================================================================================================
## Motivational Buckets
### 1) (size: 22) RTextTools has largely been used for topic classification in the social sciences. However, recent applications at various universities have demonstrated (ED: to a smaller extent) that the package can be applied to a host of problems in the natural sciences as well [1].
### 1.1) (size: 13) Jurka wrote a script that trains NINE (9) classifiers on characteristics such as clump thickness, uniformity of cell size, uniformity of cell shape, marginal adhesion, single epithelial cell size, bare nuclei, bland chromatin, normal nucleoli, and mitoses. The outcome variable is the LAST column of the data frame, which is used to identify a breast cancer as benign or malignant.
### 1.2) (size: 22) When run on the data, the classifiers were able to achieve up to 96% recall accuracy on a randomly sampled training set of 200 patients and test set of 400 patients.

```{r}
suppressPackageStartupMessages(require(RTextTools))
data <- read.csv("http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data", header=FALSE)
```
### 1.1.1) (size: 2) We explore the raw data, which is the Wisconsin Diagnostic Breast Cancer Dataset from UC Irvine. The file is downloaded EACH time we run the R script. However, we may increase execution speed by saving the processed data later as an RDA file and to load that file instead.
### 1.1.2) We note that there are ELEVEN (11) columns in the raw data, but ONLY columns TWO (2) to ELEVEN (11) are used in our analysis.

```{r}
names(data)
head(data)
```
```{r}
data <- data[-1]
thick <- as.vector(apply(as.matrix(data[1], mode="character"),1,paste,"clump",sep="",collapse=""))
size <- as.vector(apply(as.matrix(data[2], mode="character"),1,paste,"size",sep="",collapse=""))
shape <- as.vector(apply(as.matrix(data[3], mode="character"),1,paste,"shape",sep="",collapse=""))
adhesion <- as.vector(apply(as.matrix(data[4], mode="character"),1,paste,"adhesion",sep="",collapse=""))
single <- as.vector(apply(as.matrix(data[5], mode="character"),1,paste,"single",sep="",collapse=""))
nuclei <- as.vector(apply(as.matrix(data[6], mode="character"),1,paste,"nuclei",sep="",collapse=""))
chromatin <- as.vector(apply(as.matrix(data[7], mode="character"),1,paste,"chromatin",sep="",collapse=""))
nucleoli <- as.vector(apply(as.matrix(data[8], mode="character"),1,paste,"nucleoli",sep="",collapse=""))
mitoses <- as.vector(apply(as.matrix(data[9], mode="character"),1,paste,"mitoses",sep="",collapse=""))
training_data <- cbind(data[10],thick,size,shape,adhesion,single,nuclei,chromatin,nucleoli,mitoses)
```
### 1.1.3) (size: 13) The processed data can be saved as an RDA file here, after transforming the numerical columns into characters.
### 1.1.4) It is apparent that the predictors used are first converted into character by appending a text to EACH numerical value. The reason I can think of is that it is either (a) a limitation of the RTextTools package; or (b) it is more robust and efficient to do so using the package.

```{r}
source("C:/Users/denbrige/100 FxOption/103 FxOptionVerBack/080 Fx Git/R-source/PlusReg.R", echo=FALSE)
cancer.str <- paste0(RegGetRNonSourceDir(),"Jurka_02_cancer.rda")
if( !file.exists(cancer.str) )
{
  save(training_data, file=cancer.str)
}
head(training_data)
```
```{r}
training_data <- training_data[sample(1:699,size=600,replace=FALSE),]
training_codes <- training_data[1]
training_data <- training_data[-1]
```
### 1.2.1) (size: 16) First, to ensure a reproducible research, the function set.seed() should be used. However, the author does NOT use this function before sampling 600 rows from the data. An issue here is why didn't the author just use ALL 699 rows in the data? The only reason I can think of is that he is applying the bootstrapping method, however this method requires sampling WITH replacement.
### 1.2.2) The sample of 600 rows is also broken into TWO (2) data frames: (a) training_codes contains the outcome variable; and (b) training_data contains NINE (9) predictors.
### 1.2.3) The outcome values can be changed here by just modifying the values in training_codes, which is a binary outcome consisting of an integer value TWO (2) OR FOUR (4). Would the recall accuracy DECREASE if we modify the outcome values?
### 1.2.4) The predictor values can be changed here by modifying the values in training_data. We could for example, randomizing missing values (NA) and observe how the models would handle missing data? 
### 1.2.5) For a model that has a binary outcome, it is suggested that a logistic regression be applied rather than a linear regression. However, the topic of logistic regression is beyond the scope of this analysis.

```{r}
class(training_codes)
head(training_codes)
class(training_data)
head(training_data)
table(training_codes)
tMissingData <- training_data[1]
for( i in 1:10 )
{
  r <- sample(1:nrow(tMissingData), size=1, replace=FALSE)
  c <- sample(1:ncol(tMissingData), size=1, replace=FALSE)
  tMissingData[r,c] <- NA
}
```
```{r}
matrix <- create_matrix(training_data, language="english", removeNumbers=FALSE, stemWords=FALSE, removePunctuation=FALSE, weighting=weightTfIdf)
container <- create_container(matrix,t(training_codes),trainSize=1:200, testSize=201:600,virgin=FALSE)
models <- train_models(container, algorithms=c("MAXENT","SVM","GLMNET","SLDA","TREE","BAGGING","BOOSTING","RF"))
```
### 1.2.5) (size: 19) The RTextTools package [2] is a wrapper for the tm package [3]. Therefore, the steps for training a model MUST be as follows: (i) Create a document-term matrix; (ii) Create a container; (iii) Feed the container to the machine learning algorithm.
### 1.2.6) To create a matrix, you need to pass it a either a character vector, e.g. data$Text, or a data frame of columns containing predictors ONLY. There are some important parameters, such as: (i) language (default: "english"), (ii) minWordLength (default: 3) - a word should contain AT LEAST this number of letters to be included in the matrix, (iii) removeNumbers (default: FALSE) - to specify whether to remove numbers; (iv) removePunctuation (default: TRUE) - to specify whether to remove punctuations; (v) stemWords (default: FALSE) - to specify whether to remove stemwords, e.g. "ing", (vi) weighting (default: weightTf) - this parameter is from the package tm.
### 1.2.7) For example, to create a matrix using a character vector, e.g. data$Text, then you should apply the parameters: (i) language="english"; (ii) minWordLength=3; (iii) removeNumbers=TRUE; (iv) removePunctuation=TRUE; and (v) stemWords=TRUE.
### 1.2.8) As another example, should you pass it a hand-coded data frame, e.g. breast cancer, then you should apply the following parameters: (i) language="english"; (ii) minWordLength=3; (iii) removeNumbers=FALSE; (iv) removePunctuation=FALSE; and (v) stemWords=FALSE.
### 1.2.9) To create a container, you need to pass it BOTH a document-term matrix AND an outcome vector, e.g. data$Topic. The important parameters are: (i) trainSize (default: NULL) - a range specifying the row numbers in the matrix to use for training the model; (ii) testSize (default: NULL) - a range specifying the row numbers in the matrix to use for out-of-sample testing; (iii) virgin - to specify whether to treat the classification data as virgin data (recommended: FALSE).
### 1.2.10) To create a model, you need to pass it a container. The most important parameter is algorithm - a string to specify which algorithm to use. For expediency, users replicating this analysis may want to use just the three low-memory algorithms: (i) "SVM" - Support Vector Machines; (ii) "GLMNET"; and (iii) "MAXENT" - Maximum Entrophy [2]. A convenience train_models() function trains all models at once by passing in a vector of model requests, while the print_algorithms() function list ALL NINE (9) available algorithms.

```{r}
missing.dtm <- create_matrix(tMissingData, language="english", removeNumbers=FALSE, stemWords=FALSE, removePunctuation=FALSE, weighting=weightTfIdf)
missing.ctn <- create_container(missing.dtm, t(training_codes),trainSize=1:200, testSize=201:600,virgin=FALSE)
missing.models <- train_models(missing.ctn, algorithms=c("MAXENT","SVM","GLMNET","SLDA","TREE","BAGGING","BOOSTING","RF"))
```
```{r}
results <- classify_models(container, models)
analytics <- create_analytics(container, results)
analytics@ensemble_summary
```
### 1.2.11) (size: 22) 

```{r}
missing.results <- classify_models(missing.ctn, missing.models)
missing.analytics <- create_analytics(missing.ctn, missing.results)
missing.analytics@ensemble_summary
```

## References
### Jurka, RTextTools: a machine learning library for text classification. URL: http://www.rtexttools.com/. Accessed on 18-Feb-2013
### Jurka et al (2012), RTextTools: A Supervised Learning Package for Text Classification.
### Feinerer, K. Hornik and D. Meyer. Text Mining Infrastructure in R. Journal of Statistical Software, 25
(5). 2008. URL http://www.jstatsoft.org/v25/i05/.